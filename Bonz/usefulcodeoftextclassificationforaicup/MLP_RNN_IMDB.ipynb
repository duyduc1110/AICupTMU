{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import tarfile\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "filepath = \"../Dataset/IMDB/aclImdb_v1.tar.gz\"\n",
    "if not os.path.isfile(filepath):\n",
    "    result = urllib.request.urlretrieve(url, filepath)\n",
    "    print('download: ', result)\n",
    "    \n",
    "if not os.path.exists(\"../Dataset/IMDB/aclImdb\"):\n",
    "    tfile = tarfile.open(\"../Dataset/IMDB/aclImdb_v1.tar.gz\", 'r:gz')\n",
    "    result = tfile.extractall('../Dataset/IMDB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def rm_tags(text):\n",
    "    re_tag = re.compile(r'<[^>]+>')\n",
    "    return re_tag.sub('', text)\n",
    "\n",
    "def read_files(filetype):\n",
    "    path = \"../Dataset/IMDB/aclImdb/\"\n",
    "    file_list = []\n",
    "    \n",
    "    positive_path = path + filetype + \"/pos/\"\n",
    "    for f in os.listdir(positive_path):\n",
    "        file_list += [positive_path + f]\n",
    "        \n",
    "    negative_path = path + filetype + \"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list += [negative_path + f]\n",
    "        \n",
    "    print('read', filetype, 'files: ', len(file_list))\n",
    "    \n",
    "    all_labels = ([1] * 12500 + [0] * 12500)    \n",
    "    all_texts = []\n",
    "    \n",
    "    for fi in file_list:\n",
    "        with open(fi, encoding = 'utf8') as file_input:\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "            \n",
    "    return all_labels, all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files:  25000\n",
      "read test files:  25000\n",
      "For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "y_train, train_text = read_files(\"train\")\n",
    "y_test, test_text = read_files(\"test\")\n",
    "print (train_text[0])\n",
    "print (y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yung-chunchang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "token = Tokenizer(num_words = 4000)\n",
    "token.fit_on_texts(train_text)\n",
    "print(token.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pad_sequences length= 43\n",
      "[14, 3, 16, 11, 210, 53, 1157, 46, 248, 22, 3, 172, 4, 902, 3558, 14, 10, 1524, 833, 3, 16, 117, 912, 6, 161, 158, 6, 3, 132, 1, 105, 6, 31, 1551, 2030, 102, 14, 1604, 1, 1787, 13, 3, 564]\n",
      "After pad_sequences length= 400\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0   14    3   16   11  210   53 1157\n",
      "   46  248   22    3  172    4  902 3558   14   10 1524  833    3   16\n",
      "  117  912    6  161  158    6    3  132    1  105    6   31 1551 2030\n",
      "  102   14 1604    1 1787   13    3  564]\n"
     ]
    }
   ],
   "source": [
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen = 400)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen = 400)\n",
    "\n",
    "print('Before pad_sequences length=', len(x_train_seq[0]))\n",
    "print(x_train_seq[0])\n",
    "\n",
    "print('After pad_sequences length=', len(x_train[0]))\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 32)           128000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,405,313\n",
      "Trainable params: 3,405,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.4688 - acc: 0.7604 - val_loss: 0.4380 - val_acc: 0.8060\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.1908 - acc: 0.9286 - val_loss: 0.4756 - val_acc: 0.8076\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.0714 - acc: 0.9769 - val_loss: 0.5942 - val_acc: 0.8062\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.0255 - acc: 0.9931 - val_loss: 0.8665 - val_acc: 0.7820\n",
      "Epoch 5/10\n",
      " - 8s - loss: 0.0135 - acc: 0.9958 - val_loss: 1.1528 - val_acc: 0.7506\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.0092 - acc: 0.9973 - val_loss: 0.9219 - val_acc: 0.8058\n",
      "Epoch 7/10\n",
      " - 9s - loss: 0.0123 - acc: 0.9959 - val_loss: 1.0735 - val_acc: 0.7902\n",
      "Epoch 8/10\n",
      " - 9s - loss: 0.0123 - acc: 0.9960 - val_loss: 1.3523 - val_acc: 0.7524\n",
      "Epoch 9/10\n",
      " - 9s - loss: 0.0141 - acc: 0.9951 - val_loss: 1.0005 - val_acc: 0.8158\n",
      "Epoch 10/10\n",
      " - 9s - loss: 0.0171 - acc: 0.9942 - val_loss: 1.2344 - val_acc: 0.7852\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim = 32, input_dim = 4000, input_length = 400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "train_history = model.fit(x_train, y_train, batch_size = 100, epochs = 10, verbose = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 25s 1ms/step\n",
      "0.8552\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose = 1)\n",
    "print(scores[0])\n",
    "predict = model.predict_classes(x_test)\n",
    "print(predict[:10])\n",
    "predict_classes = predict.reshape(-1)\n",
    "print(predict_classes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like this show. It has drama, romance, and comedy all rolled into one. I am 28 and I am a married mother, so I can identify both with Lorelei's and Rory's experiences in the show. I have been watching mostly the repeats on the Family Channel lately, so I am not up-to-date on what is going on now. I think females would like this show more than males, but I know some men out there would enjoy it! I really like that is an hour long and not a half hour, as th hour seems to fly by when I am watching it! Give it a chance if you have never seen the show! I think Lorelei and Luke are my favorite characters on the show though, mainly because of the way they are with one another. How could you not see something was there (or take that long to see it I guess I should say)? Happy viewing!\n",
      "Label:  positive Prediction:  positive\n"
     ]
    }
   ],
   "source": [
    "SentimentDict = {1: 'positive', 0: 'negative'}\n",
    "def display_test_Sentiment(idx):\n",
    "    print(test_text[idx])\n",
    "    print('Label: ', SentimentDict[y_test[idx]], \n",
    "          'Prediction: ', SentimentDict[predict_classes[idx]])\n",
    "\n",
    "display_test_Sentiment(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321, 12, 52, 5, 25, 31, 1044, 17, 258, 46, 67, 45, 1044, 384, 257, 15, 87, 27, 2431, 108, 423, 19, 209, 45, 527, 230, 1745, 45, 2382, 19, 639, 1768, 6, 3, 354, 2, 1, 222, 18, 257, 1, 376, 760, 319, 1643, 59, 62, 1, 823, 581, 4, 3, 18, 2, 885, 8, 443, 13, 48, 17, 20, 83]\n",
      "62\n",
      "400\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Infinity War was hyped up to be an incredible spectacle, but although there were some incredible moments, especially with most one-liners being absolutely on point, some parts feel unnecessary; some drag on somewhat (Vision is a boring chap); and the whole film, especially the start, feels overtly Star Wars-y, which really confuses the viewing experience of a Marvel film, and leaves it overall as acceptably good, but not great.\"\n",
    "input_seq = token.texts_to_sequences([input_text])\n",
    "print(input_seq[0])\n",
    "print(len(input_seq[0]))\n",
    "\n",
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen = 400)\n",
    "print(len(pad_input_seq[0]))\n",
    "\n",
    "predict_result = model.predict_classes(pad_input_seq)\n",
    "predict_result[0][0]\n",
    "\n",
    "print(SentimentDict[predict_result[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "def predict_review(input_text):\n",
    "    input_seq = token.texts_to_sequences([input_text])\n",
    "    pad_input_seq = sequence.pad_sequences(input_seq, maxlen = 400)\n",
    "    predict_result = model.predict_classes(pad_input_seq)\n",
    "    print(SentimentDict[predict_result[0][0]])\n",
    "    \n",
    "predict_review(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 400, 32)           128000    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400, 32)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 133,393\n",
      "Trainable params: 133,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: 0.5699 - acc: 0.7071 - val_loss: 0.3876 - val_acc: 0.8432\n",
      "Epoch 2/10\n",
      " - 15s - loss: 0.3429 - acc: 0.8602 - val_loss: 0.5632 - val_acc: 0.7530\n",
      "Epoch 3/10\n",
      " - 16s - loss: 0.3035 - acc: 0.8795 - val_loss: 0.7156 - val_acc: 0.6964\n",
      "Epoch 4/10\n",
      " - 16s - loss: 0.2639 - acc: 0.8968 - val_loss: 0.6612 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 15s - loss: 0.2128 - acc: 0.9199 - val_loss: 0.5390 - val_acc: 0.8146\n",
      "Epoch 6/10\n",
      " - 16s - loss: 0.1759 - acc: 0.9327 - val_loss: 0.8394 - val_acc: 0.7400\n",
      "Epoch 7/10\n",
      " - 15s - loss: 0.1389 - acc: 0.9483 - val_loss: 0.9565 - val_acc: 0.7150\n",
      "Epoch 8/10\n",
      " - 15s - loss: 0.1236 - acc: 0.9558 - val_loss: 1.0165 - val_acc: 0.7258\n",
      "Epoch 9/10\n",
      " - 16s - loss: 0.0998 - acc: 0.9650 - val_loss: 0.9700 - val_acc: 0.7724\n",
      "Epoch 10/10\n",
      " - 16s - loss: 0.0874 - acc: 0.9685 - val_loss: 0.9176 - val_acc: 0.7818\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim = 32, input_dim = 4000, input_length = 400))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(SimpleRNN(units = 16)) #number of RNN layers\n",
    "model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "train_history = model.fit(x_train, y_train, batch_size = 100, epochs = 10, verbose = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 12s 475us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose = 1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 400, 32)           128000    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 400, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 135,745\n",
      "Trainable params: 135,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 50s - loss: 0.4971 - acc: 0.7488 - val_loss: 0.5397 - val_acc: 0.7554\n",
      "Epoch 2/10\n",
      " - 49s - loss: 0.2806 - acc: 0.8881 - val_loss: 0.4927 - val_acc: 0.8010\n",
      "Epoch 3/10\n",
      " - 48s - loss: 0.2298 - acc: 0.9101 - val_loss: 0.4479 - val_acc: 0.8432\n",
      "Epoch 4/10\n",
      " - 50s - loss: 0.1997 - acc: 0.9241 - val_loss: 0.5758 - val_acc: 0.7732\n",
      "Epoch 5/10\n",
      " - 50s - loss: 0.1786 - acc: 0.9325 - val_loss: 0.4735 - val_acc: 0.8252\n",
      "Epoch 6/10\n",
      " - 49s - loss: 0.1599 - acc: 0.9401 - val_loss: 0.5854 - val_acc: 0.8082\n",
      "Epoch 7/10\n",
      " - 48s - loss: 0.1429 - acc: 0.9474 - val_loss: 0.6051 - val_acc: 0.8074\n",
      "Epoch 8/10\n",
      " - 47s - loss: 0.1239 - acc: 0.9548 - val_loss: 0.4601 - val_acc: 0.8340\n",
      "Epoch 9/10\n",
      " - 48s - loss: 0.1178 - acc: 0.9572 - val_loss: 0.7646 - val_acc: 0.7868\n",
      "Epoch 10/10\n",
      " - 48s - loss: 0.1042 - acc: 0.9617 - val_loss: 0.7472 - val_acc: 0.7992\n"
     ]
    }
   ],
   "source": [
    "#add LSTM layer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim = 32, input_dim = 4000, input_length = 400))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(LSTM(units = 16))\n",
    "model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "train_history = model.fit(x_train, y_train, batch_size = 100, epochs = 10, verbose = 2, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 25s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8552"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose = 1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
