{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import operator\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import numpy as np\n",
    "from gensim.models import word2vec, KeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize, sent_tokenize, WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from numpy import asarray, zeros\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Embedding, Dense, Dropout, CuDNNGRU, CuDNNLSTM, Bidirectional\n",
    "from keras.layers import Input, Conv1D, GlobalMaxPooling1D, Flatten, Activation, SpatialDropout1D, BatchNormalization\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title tokenized: \n",
      "['a', 'brain', 'inspired', 'trust', 'management', 'model', 'to', 'assure', 'security', 'in', 'a', 'cloud', 'based', 'iot', 'framework', 'for', 'neuroscience', 'applications']\n",
      "\n",
      "Train titles sequences feed to Embedding layer: \n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    4  353  915  993  142   23   12 9123  134    5    4  121   10\n",
      "  405   41    1 4205   60]\n",
      "\n",
      "Max length of titles: 33\n",
      "\n",
      "Sample of word index: \n",
      "[('for', 1), ('of', 2), ('and', 3), ('a', 4), ('in', 5)]\n",
      "\n",
      "Vocabulary size:  18845\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    with open(r'../'+filename, encoding='utf-8') as f:\n",
    "        data = f.read().split('\\n')\n",
    "        data = data[:len(data)-1] #Clear last null row\n",
    "        f.close()\n",
    "    data = [row for row in csv.reader(data, quotechar='\"', delimiter=',',quoting=csv.QUOTE_ALL, skipinitialspace=True)]\n",
    "    data = pd.DataFrame(data[1:], columns = data[0]) #Transform to Pandas DataFrame\n",
    "    return data\n",
    "\n",
    "def preprocess(text):\n",
    "    STOPWORDS = set(stopwords.words(\"english\"))\n",
    "    text= text.strip().lower().split(' ')\n",
    "    text = filter(lambda word: word not in STOPWORDS, text)\n",
    "    return \" \".join(text)\n",
    "\n",
    "def categorical_label(df):\n",
    "    df['EMPIRICAL'] = [1 if 'EMPIRICAL' in df.loc[i, 'Task 2'] else 0 for i in range(len(df))]\n",
    "    df['ENGINEERING'] = [1 if 'ENGINEERING' in df.loc[i, 'Task 2'] else 0 for i in range(len(df))]\n",
    "    df['THEORETICAL'] = [1 if 'THEORETICAL' in df.loc[i, 'Task 2'] else 0 for i in range(len(df))]\n",
    "    df['OTHERS'] = [1 if 'OTHERS' in df.loc[i, 'Task 2'] else 0 for i in range(len(df))]\n",
    "    \n",
    "def tokenize_title():\n",
    "    titles = pd.concat([train_df['Title'],test_df['Title']], ignore_index=True)\n",
    "    \n",
    "    #Using keras tokenizer to encode and decode \n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(titles)\n",
    "    new_titles = [text_to_word_sequence(sen) for sen in titles] #new tokenizered titles\n",
    "    \n",
    "    #Texts to sequences\n",
    "    train_titles_encoded = t.texts_to_sequences(train_df['Title'])\n",
    "    test_titles_encoded = t.texts_to_sequences(test_df['Title'])\n",
    "\n",
    "    #pad sequences\n",
    "    max_title_len = max([len(sen) for sen in new_titles]) #max length of abstract\n",
    "    train_titles_sequences = pad_sequences(train_titles_encoded, maxlen=max_title_len)\n",
    "    test_titles_sequences = pad_sequences(test_titles_encoded, maxlen=max_title_len)\n",
    "\n",
    "    #get word index and vocab size\n",
    "    word_index = t.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    return new_titles, train_titles_sequences, test_titles_sequences, max_title_len, word_index, vocab_size\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #read file\n",
    "    train_df = read_file('task2_trainset.csv')\n",
    "    test_df = read_file('task2_public_testset.csv')\n",
    "    \n",
    "    #Use this if want to remove stopwords in Abstract\n",
    "    #train_df['Abstract'] = train_df['Abstract'].apply(preprocess)\n",
    "    #test_df['Abstract'] = test_df['Abstract'].apply(preprocess)\n",
    "    \n",
    "    categorical_label(train_df) #Categorical label to multiple columns\n",
    "    new_titles, train_titles_sequences, test_titles_sequences, max_title_len, word_index, vocab_size = tokenize_title()\n",
    "    \n",
    "    print('Title tokenized: \\n{}\\n'.format(new_titles[0]))\n",
    "    print('Train titles sequences feed to Embedding layer: \\n{}\\n'.format(train_titles_sequences[0]))\n",
    "    print('Max length of titles: {}\\n'.format(max_title_len))\n",
    "    print('Sample of word index: \\n{}\\n'.format(list(word_index.items())[:5]))\n",
    "    print('Vocabulary size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GloVe and create Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 4218\n",
      "Vocab size:  18845\n"
     ]
    }
   ],
   "source": [
    "def load_glove(dim):\n",
    "    glove_vector = dict()\n",
    "    f = open(r'./glove.6B/glove.6B.'+str(dim)+r'd.txt', encoding='utf-8')\n",
    "    for line in tqdm(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = asarray(values[1:], dtype='float32')\n",
    "        glove_vector[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded {} word vectors'.format(len(glove_vector)))\n",
    "    return glove_vector\n",
    "\n",
    "def create_emb_mtrx(word_vector):\n",
    "    embedding_matrix = zeros((vocab_size, 300))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = word_vector.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #glove_vector = load_glove(300) #Load GloVe vector, dimension = [50,100,200,300]. I chose the largest, ok?\n",
    "    embedding_matrix = create_emb_mtrx(glove_vector)\n",
    "    print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "    print('Vocab size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RNN Model\n",
    "Embedding Layer -> 2 BiLSTM -> Dense -> Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_layer = Embedding(vocab_size,\n",
    "                     embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_title_len,\n",
    "                     trainable=False)\n",
    "\n",
    "# Inputs\n",
    "title_input = Input(shape=(max_title_len,), dtype='int32')\n",
    "embedded_sequences = wv_layer(title_input)\n",
    "\n",
    "# biGRU\n",
    "embedded_sequences = SpatialDropout1D(0.2)(embedded_sequences)\n",
    "x = Bidirectional(CuDNNLSTM(32, return_sequences=True))(embedded_sequences)\n",
    "x = Bidirectional(CuDNNLSTM(32, return_sequences=False))(x)\n",
    "\n",
    "# Output\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "#preds = Dense(1, activation='sigmoid')(x) #1 model/label\n",
    "preds = Dense(4, activation='sigmoid')(x) #1 model/4 labels\n",
    "\n",
    "# build the model\n",
    "model = Model(inputs=[title_input], outputs=preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001, clipnorm=.25, beta_1=0.7, beta_2=0.99),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, 33, 300)           5653500   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_11 (Spatia (None, 33, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 33, 64)            85504     \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 64)                25088     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 5,765,264\n",
      "Trainable params: 111,732\n",
      "Non-trainable params: 5,653,532\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/100\n",
      "6300/6300 [==============================] - ETA: 11s - loss: 0.7877 - accuracy: 0.502 - ETA: 2s - loss: 0.7645 - accuracy: 0.516 - ETA: 0s - loss: 0.7496 - accuracy: 0.52 - ETA: 0s - loss: 0.7376 - accuracy: 0.52 - 2s 248us/step - loss: 0.7304 - accuracy: 0.5347 - val_loss: 0.6870 - val_accuracy: 0.6232\n",
      "Epoch 2/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.56 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6808 - accuracy: 0.58 - ETA: 0s - loss: 0.6741 - accuracy: 0.59 - 0s 45us/step - loss: 0.6717 - accuracy: 0.5959 - val_loss: 0.6653 - val_accuracy: 0.7204\n",
      "Epoch 3/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.63 - ETA: 0s - loss: 0.6413 - accuracy: 0.64 - ETA: 0s - loss: 0.6415 - accuracy: 0.65 - ETA: 0s - loss: 0.6379 - accuracy: 0.66 - 0s 44us/step - loss: 0.6365 - accuracy: 0.6650 - val_loss: 0.6519 - val_accuracy: 0.7118\n",
      "Epoch 4/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.69 - ETA: 0s - loss: 0.6193 - accuracy: 0.69 - ETA: 0s - loss: 0.6189 - accuracy: 0.69 - ETA: 0s - loss: 0.6154 - accuracy: 0.70 - 0s 42us/step - loss: 0.6138 - accuracy: 0.7054 - val_loss: 0.6391 - val_accuracy: 0.7218\n",
      "Epoch 5/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.73 - ETA: 0s - loss: 0.5988 - accuracy: 0.72 - ETA: 0s - loss: 0.5993 - accuracy: 0.72 - ETA: 0s - loss: 0.6004 - accuracy: 0.72 - 0s 43us/step - loss: 0.5981 - accuracy: 0.7298 - val_loss: 0.6220 - val_accuracy: 0.7325\n",
      "Epoch 6/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.5930 - accuracy: 0.71 - ETA: 0s - loss: 0.5855 - accuracy: 0.74 - ETA: 0s - loss: 0.5812 - accuracy: 0.74 - ETA: 0s - loss: 0.5800 - accuracy: 0.74 - 0s 42us/step - loss: 0.5788 - accuracy: 0.7466 - val_loss: 0.6051 - val_accuracy: 0.7539\n",
      "Epoch 7/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.5701 - accuracy: 0.74 - ETA: 0s - loss: 0.5629 - accuracy: 0.76 - ETA: 0s - loss: 0.5622 - accuracy: 0.75 - ETA: 0s - loss: 0.5601 - accuracy: 0.75 - 0s 43us/step - loss: 0.5624 - accuracy: 0.7554 - val_loss: 0.5950 - val_accuracy: 0.7589\n",
      "Epoch 8/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.75 - ETA: 0s - loss: 0.5537 - accuracy: 0.75 - ETA: 0s - loss: 0.5522 - accuracy: 0.75 - ETA: 0s - loss: 0.5491 - accuracy: 0.76 - 0s 42us/step - loss: 0.5487 - accuracy: 0.7617 - val_loss: 0.5819 - val_accuracy: 0.7511\n",
      "Epoch 9/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.77 - ETA: 0s - loss: 0.5327 - accuracy: 0.77 - ETA: 0s - loss: 0.5330 - accuracy: 0.77 - ETA: 0s - loss: 0.5320 - accuracy: 0.77 - 0s 43us/step - loss: 0.5336 - accuracy: 0.7696 - val_loss: 0.5726 - val_accuracy: 0.7532\n",
      "Epoch 10/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.76 - ETA: 0s - loss: 0.5237 - accuracy: 0.77 - ETA: 0s - loss: 0.5228 - accuracy: 0.77 - ETA: 0s - loss: 0.5218 - accuracy: 0.77 - 0s 41us/step - loss: 0.5200 - accuracy: 0.7737 - val_loss: 0.5590 - val_accuracy: 0.7607\n",
      "Epoch 11/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.76 - ETA: 0s - loss: 0.5135 - accuracy: 0.77 - ETA: 0s - loss: 0.5135 - accuracy: 0.76 - ETA: 0s - loss: 0.5087 - accuracy: 0.77 - 0s 43us/step - loss: 0.5081 - accuracy: 0.7744 - val_loss: 0.5491 - val_accuracy: 0.7657\n",
      "Epoch 12/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.78 - ETA: 0s - loss: 0.5012 - accuracy: 0.78 - ETA: 0s - loss: 0.5024 - accuracy: 0.77 - ETA: 0s - loss: 0.4992 - accuracy: 0.77 - 0s 42us/step - loss: 0.4961 - accuracy: 0.7808 - val_loss: 0.5412 - val_accuracy: 0.7493\n",
      "Epoch 13/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4835 - accuracy: 0.78 - ETA: 0s - loss: 0.4865 - accuracy: 0.78 - ETA: 0s - loss: 0.4910 - accuracy: 0.77 - ETA: 0s - loss: 0.4886 - accuracy: 0.78 - 0s 42us/step - loss: 0.4864 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7550\n",
      "Epoch 14/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.79 - ETA: 0s - loss: 0.4798 - accuracy: 0.78 - ETA: 0s - loss: 0.4743 - accuracy: 0.79 - ETA: 0s - loss: 0.4768 - accuracy: 0.78 - 0s 43us/step - loss: 0.4768 - accuracy: 0.7871 - val_loss: 0.5247 - val_accuracy: 0.7632\n",
      "Epoch 15/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4607 - accuracy: 0.79 - ETA: 0s - loss: 0.4641 - accuracy: 0.79 - ETA: 0s - loss: 0.4648 - accuracy: 0.79 - ETA: 0s - loss: 0.4649 - accuracy: 0.79 - 0s 42us/step - loss: 0.4660 - accuracy: 0.7908 - val_loss: 0.5187 - val_accuracy: 0.7564\n",
      "Epoch 16/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.78 - ETA: 0s - loss: 0.4580 - accuracy: 0.79 - ETA: 0s - loss: 0.4554 - accuracy: 0.79 - ETA: 0s - loss: 0.4544 - accuracy: 0.79 - 0s 42us/step - loss: 0.4542 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7632\n",
      "Epoch 17/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.81 - ETA: 0s - loss: 0.4425 - accuracy: 0.80 - ETA: 0s - loss: 0.4467 - accuracy: 0.80 - ETA: 0s - loss: 0.4458 - accuracy: 0.80 - 0s 44us/step - loss: 0.4455 - accuracy: 0.8019 - val_loss: 0.5088 - val_accuracy: 0.7646\n",
      "Epoch 18/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.81 - ETA: 0s - loss: 0.4360 - accuracy: 0.80 - ETA: 0s - loss: 0.4405 - accuracy: 0.80 - ETA: 0s - loss: 0.4375 - accuracy: 0.80 - 0s 44us/step - loss: 0.4381 - accuracy: 0.8032 - val_loss: 0.5031 - val_accuracy: 0.7621\n",
      "Epoch 19/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.81 - ETA: 0s - loss: 0.4269 - accuracy: 0.81 - ETA: 0s - loss: 0.4272 - accuracy: 0.81 - ETA: 0s - loss: 0.4273 - accuracy: 0.81 - 0s 43us/step - loss: 0.4270 - accuracy: 0.8117 - val_loss: 0.5016 - val_accuracy: 0.7589\n",
      "Epoch 20/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4065 - accuracy: 0.82 - ETA: 0s - loss: 0.4175 - accuracy: 0.81 - ETA: 0s - loss: 0.4172 - accuracy: 0.81 - ETA: 0s - loss: 0.4192 - accuracy: 0.81 - 0s 43us/step - loss: 0.4192 - accuracy: 0.8145 - val_loss: 0.5005 - val_accuracy: 0.7554\n",
      "Epoch 21/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.82 - ETA: 0s - loss: 0.4101 - accuracy: 0.81 - ETA: 0s - loss: 0.4084 - accuracy: 0.81 - ETA: 0s - loss: 0.4122 - accuracy: 0.81 - 0s 42us/step - loss: 0.4138 - accuracy: 0.8141 - val_loss: 0.4890 - val_accuracy: 0.7636\n",
      "Epoch 22/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.82 - ETA: 0s - loss: 0.3963 - accuracy: 0.83 - ETA: 0s - loss: 0.3972 - accuracy: 0.82 - ETA: 0s - loss: 0.3990 - accuracy: 0.82 - 0s 44us/step - loss: 0.4015 - accuracy: 0.8210 - val_loss: 0.5013 - val_accuracy: 0.7404\n",
      "Epoch 23/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.82 - ETA: 0s - loss: 0.3879 - accuracy: 0.83 - ETA: 0s - loss: 0.3893 - accuracy: 0.83 - ETA: 0s - loss: 0.3927 - accuracy: 0.82 - 0s 42us/step - loss: 0.3932 - accuracy: 0.8286 - val_loss: 0.4991 - val_accuracy: 0.7446\n",
      "Epoch 24/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.84 - ETA: 0s - loss: 0.3806 - accuracy: 0.83 - ETA: 0s - loss: 0.3846 - accuracy: 0.83 - ETA: 0s - loss: 0.3845 - accuracy: 0.83 - 0s 42us/step - loss: 0.3863 - accuracy: 0.8303 - val_loss: 0.4841 - val_accuracy: 0.7654\n",
      "Epoch 25/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.85 - ETA: 0s - loss: 0.3739 - accuracy: 0.84 - ETA: 0s - loss: 0.3809 - accuracy: 0.83 - ETA: 0s - loss: 0.3803 - accuracy: 0.83 - 0s 45us/step - loss: 0.3821 - accuracy: 0.8340 - val_loss: 0.4890 - val_accuracy: 0.7586\n",
      "Epoch 26/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.82 - ETA: 0s - loss: 0.3692 - accuracy: 0.83 - ETA: 0s - loss: 0.3693 - accuracy: 0.83 - ETA: 0s - loss: 0.3695 - accuracy: 0.83 - 0s 43us/step - loss: 0.3709 - accuracy: 0.8373 - val_loss: 0.4905 - val_accuracy: 0.7536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.83 - ETA: 0s - loss: 0.3663 - accuracy: 0.84 - ETA: 0s - loss: 0.3705 - accuracy: 0.83 - ETA: 0s - loss: 0.3695 - accuracy: 0.83 - 0s 42us/step - loss: 0.3682 - accuracy: 0.8397 - val_loss: 0.4858 - val_accuracy: 0.7625\n",
      "Epoch 28/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.84 - ETA: 0s - loss: 0.3697 - accuracy: 0.84 - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - ETA: 0s - loss: 0.3638 - accuracy: 0.84 - 0s 42us/step - loss: 0.3641 - accuracy: 0.8441 - val_loss: 0.4853 - val_accuracy: 0.7564\n",
      "Epoch 29/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.85 - ETA: 0s - loss: 0.3488 - accuracy: 0.85 - ETA: 0s - loss: 0.3521 - accuracy: 0.84 - 0s 42us/step - loss: 0.3527 - accuracy: 0.8485 - val_loss: 0.4901 - val_accuracy: 0.7557\n",
      "Epoch 30/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.84 - ETA: 0s - loss: 0.3502 - accuracy: 0.85 - ETA: 0s - loss: 0.3511 - accuracy: 0.84 - ETA: 0s - loss: 0.3481 - accuracy: 0.85 - 0s 42us/step - loss: 0.3484 - accuracy: 0.8496 - val_loss: 0.4928 - val_accuracy: 0.7507\n",
      "Epoch 31/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.86 - ETA: 0s - loss: 0.3458 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3498 - accuracy: 0.84 - 0s 43us/step - loss: 0.3460 - accuracy: 0.8519 - val_loss: 0.4868 - val_accuracy: 0.7657\n",
      "Epoch 32/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.86 - ETA: 0s - loss: 0.3448 - accuracy: 0.85 - ETA: 0s - loss: 0.3395 - accuracy: 0.85 - ETA: 0s - loss: 0.3426 - accuracy: 0.85 - 0s 42us/step - loss: 0.3411 - accuracy: 0.8549 - val_loss: 0.5063 - val_accuracy: 0.7568\n",
      "Epoch 33/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.85 - ETA: 0s - loss: 0.3273 - accuracy: 0.85 - ETA: 0s - loss: 0.3327 - accuracy: 0.85 - ETA: 0s - loss: 0.3345 - accuracy: 0.85 - 0s 43us/step - loss: 0.3360 - accuracy: 0.8544 - val_loss: 0.5135 - val_accuracy: 0.7586\n",
      "Epoch 34/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.85 - ETA: 0s - loss: 0.3280 - accuracy: 0.85 - ETA: 0s - loss: 0.3312 - accuracy: 0.85 - ETA: 0s - loss: 0.3294 - accuracy: 0.85 - 0s 41us/step - loss: 0.3299 - accuracy: 0.8600 - val_loss: 0.5412 - val_accuracy: 0.7396\n",
      "Epoch 35/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.86 - ETA: 0s - loss: 0.3150 - accuracy: 0.86 - ETA: 0s - loss: 0.3139 - accuracy: 0.86 - ETA: 0s - loss: 0.3217 - accuracy: 0.86 - 0s 42us/step - loss: 0.3233 - accuracy: 0.8623 - val_loss: 0.5640 - val_accuracy: 0.7393\n",
      "Epoch 36/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3269 - accuracy: 0.85 - ETA: 0s - loss: 0.3244 - accuracy: 0.86 - ETA: 0s - loss: 0.3225 - accuracy: 0.86 - ETA: 0s - loss: 0.3201 - accuracy: 0.86 - 0s 42us/step - loss: 0.3193 - accuracy: 0.8640 - val_loss: 0.5516 - val_accuracy: 0.7371\n",
      "Epoch 37/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.87 - ETA: 0s - loss: 0.3177 - accuracy: 0.86 - ETA: 0s - loss: 0.3181 - accuracy: 0.86 - ETA: 0s - loss: 0.3176 - accuracy: 0.86 - 0s 42us/step - loss: 0.3185 - accuracy: 0.8640 - val_loss: 0.5431 - val_accuracy: 0.7507\n",
      "Epoch 38/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3146 - accuracy: 0.86 - ETA: 0s - loss: 0.3115 - accuracy: 0.86 - ETA: 0s - loss: 0.3110 - accuracy: 0.86 - 0s 42us/step - loss: 0.3116 - accuracy: 0.8663 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3079 - accuracy: 0.87 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3085 - accuracy: 0.87 - 0s 41us/step - loss: 0.3077 - accuracy: 0.8720 - val_loss: 0.5554 - val_accuracy: 0.7361\n",
      "Epoch 40/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3005 - accuracy: 0.87 - ETA: 0s - loss: 0.2975 - accuracy: 0.87 - ETA: 0s - loss: 0.3031 - accuracy: 0.86 - ETA: 0s - loss: 0.2989 - accuracy: 0.87 - 0s 42us/step - loss: 0.3022 - accuracy: 0.8702 - val_loss: 0.5403 - val_accuracy: 0.7568\n",
      "Epoch 41/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.87 - ETA: 0s - loss: 0.3068 - accuracy: 0.86 - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - ETA: 0s - loss: 0.3018 - accuracy: 0.87 - 0s 41us/step - loss: 0.3004 - accuracy: 0.8728 - val_loss: 0.5420 - val_accuracy: 0.7518\n",
      "Epoch 42/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - ETA: 0s - loss: 0.2979 - accuracy: 0.87 - ETA: 0s - loss: 0.2972 - accuracy: 0.87 - ETA: 0s - loss: 0.2971 - accuracy: 0.87 - 0s 42us/step - loss: 0.2983 - accuracy: 0.8743 - val_loss: 0.5468 - val_accuracy: 0.7368\n",
      "Epoch 43/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.87 - ETA: 0s - loss: 0.2928 - accuracy: 0.87 - ETA: 0s - loss: 0.2886 - accuracy: 0.87 - ETA: 0s - loss: 0.2900 - accuracy: 0.87 - 0s 42us/step - loss: 0.2910 - accuracy: 0.8772 - val_loss: 0.5594 - val_accuracy: 0.7496\n",
      "Epoch 44/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.88 - ETA: 0s - loss: 0.2897 - accuracy: 0.87 - ETA: 0s - loss: 0.2928 - accuracy: 0.87 - ETA: 0s - loss: 0.2921 - accuracy: 0.87 - 0s 42us/step - loss: 0.2905 - accuracy: 0.8760 - val_loss: 0.5778 - val_accuracy: 0.7454\n",
      "Epoch 45/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.88 - ETA: 0s - loss: 0.2794 - accuracy: 0.88 - ETA: 0s - loss: 0.2822 - accuracy: 0.88 - ETA: 0s - loss: 0.2835 - accuracy: 0.88 - 0s 41us/step - loss: 0.2826 - accuracy: 0.8823 - val_loss: 0.5816 - val_accuracy: 0.7489\n",
      "Epoch 46/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2996 - accuracy: 0.86 - ETA: 0s - loss: 0.2864 - accuracy: 0.88 - ETA: 0s - loss: 0.2803 - accuracy: 0.88 - ETA: 0s - loss: 0.2823 - accuracy: 0.88 - 0s 42us/step - loss: 0.2805 - accuracy: 0.8821 - val_loss: 0.5837 - val_accuracy: 0.7529\n",
      "Epoch 47/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2646 - accuracy: 0.89 - ETA: 0s - loss: 0.2640 - accuracy: 0.89 - ETA: 0s - loss: 0.2685 - accuracy: 0.88 - ETA: 0s - loss: 0.2715 - accuracy: 0.88 - 0s 44us/step - loss: 0.2726 - accuracy: 0.8858 - val_loss: 0.5762 - val_accuracy: 0.7436\n",
      "Epoch 48/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.88 - ETA: 0s - loss: 0.2685 - accuracy: 0.89 - ETA: 0s - loss: 0.2729 - accuracy: 0.88 - ETA: 0s - loss: 0.2716 - accuracy: 0.88 - 0s 42us/step - loss: 0.2710 - accuracy: 0.8866 - val_loss: 0.6188 - val_accuracy: 0.7325\n",
      "Epoch 49/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.89 - ETA: 0s - loss: 0.2599 - accuracy: 0.89 - ETA: 0s - loss: 0.2631 - accuracy: 0.89 - ETA: 0s - loss: 0.2670 - accuracy: 0.88 - 0s 42us/step - loss: 0.2686 - accuracy: 0.8868 - val_loss: 0.5895 - val_accuracy: 0.7418\n",
      "Epoch 50/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.89 - ETA: 0s - loss: 0.2550 - accuracy: 0.89 - ETA: 0s - loss: 0.2633 - accuracy: 0.89 - ETA: 0s - loss: 0.2651 - accuracy: 0.88 - 0s 42us/step - loss: 0.2669 - accuracy: 0.8874 - val_loss: 0.6414 - val_accuracy: 0.7436\n",
      "Epoch 51/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.89 - ETA: 0s - loss: 0.2557 - accuracy: 0.89 - ETA: 0s - loss: 0.2603 - accuracy: 0.89 - ETA: 0s - loss: 0.2612 - accuracy: 0.89 - 0s 43us/step - loss: 0.2623 - accuracy: 0.8918 - val_loss: 0.6145 - val_accuracy: 0.7461\n",
      "Epoch 52/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.89 - ETA: 0s - loss: 0.2597 - accuracy: 0.88 - ETA: 0s - loss: 0.2623 - accuracy: 0.88 - ETA: 0s - loss: 0.2608 - accuracy: 0.88 - 0s 42us/step - loss: 0.2608 - accuracy: 0.8899 - val_loss: 0.6661 - val_accuracy: 0.7264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2445 - accuracy: 0.90 - ETA: 0s - loss: 0.2531 - accuracy: 0.89 - ETA: 0s - loss: 0.2511 - accuracy: 0.89 - ETA: 0s - loss: 0.2537 - accuracy: 0.89 - 0s 42us/step - loss: 0.2545 - accuracy: 0.8962 - val_loss: 0.6576 - val_accuracy: 0.7332\n",
      "Epoch 54/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.89 - ETA: 0s - loss: 0.2522 - accuracy: 0.89 - ETA: 0s - loss: 0.2525 - accuracy: 0.89 - ETA: 0s - loss: 0.2518 - accuracy: 0.89 - 0s 42us/step - loss: 0.2540 - accuracy: 0.8955 - val_loss: 0.6484 - val_accuracy: 0.7521\n",
      "Epoch 55/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.90 - ETA: 0s - loss: 0.2381 - accuracy: 0.89 - ETA: 0s - loss: 0.2419 - accuracy: 0.89 - ETA: 0s - loss: 0.2468 - accuracy: 0.89 - 0s 42us/step - loss: 0.2473 - accuracy: 0.8961 - val_loss: 0.6645 - val_accuracy: 0.7396\n",
      "Epoch 56/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.90 - ETA: 0s - loss: 0.2431 - accuracy: 0.89 - ETA: 0s - loss: 0.2458 - accuracy: 0.89 - ETA: 0s - loss: 0.2448 - accuracy: 0.89 - 0s 42us/step - loss: 0.2462 - accuracy: 0.8965 - val_loss: 0.6460 - val_accuracy: 0.7425\n",
      "Epoch 57/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.89 - ETA: 0s - loss: 0.2408 - accuracy: 0.89 - ETA: 0s - loss: 0.2407 - accuracy: 0.89 - ETA: 0s - loss: 0.2396 - accuracy: 0.89 - 0s 42us/step - loss: 0.2409 - accuracy: 0.8975 - val_loss: 0.6539 - val_accuracy: 0.7450\n",
      "Epoch 58/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.89 - ETA: 0s - loss: 0.2312 - accuracy: 0.90 - ETA: 0s - loss: 0.2373 - accuracy: 0.90 - ETA: 0s - loss: 0.2376 - accuracy: 0.90 - 0s 42us/step - loss: 0.2390 - accuracy: 0.9004 - val_loss: 0.7186 - val_accuracy: 0.7361\n",
      "Epoch 59/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.90 - ETA: 0s - loss: 0.2301 - accuracy: 0.90 - ETA: 0s - loss: 0.2360 - accuracy: 0.90 - ETA: 0s - loss: 0.2382 - accuracy: 0.89 - 0s 43us/step - loss: 0.2364 - accuracy: 0.9006 - val_loss: 0.6851 - val_accuracy: 0.7275\n",
      "Epoch 60/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.90 - ETA: 0s - loss: 0.2290 - accuracy: 0.90 - ETA: 0s - loss: 0.2309 - accuracy: 0.90 - ETA: 0s - loss: 0.2345 - accuracy: 0.90 - 0s 45us/step - loss: 0.2345 - accuracy: 0.9025 - val_loss: 0.6830 - val_accuracy: 0.7482\n",
      "Epoch 61/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.90 - ETA: 0s - loss: 0.2253 - accuracy: 0.90 - ETA: 0s - loss: 0.2287 - accuracy: 0.90 - ETA: 0s - loss: 0.2320 - accuracy: 0.90 - 0s 43us/step - loss: 0.2328 - accuracy: 0.9028 - val_loss: 0.7129 - val_accuracy: 0.7218\n",
      "Epoch 62/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.90 - ETA: 0s - loss: 0.2272 - accuracy: 0.90 - ETA: 0s - loss: 0.2259 - accuracy: 0.90 - ETA: 0s - loss: 0.2257 - accuracy: 0.90 - 0s 44us/step - loss: 0.2276 - accuracy: 0.9066 - val_loss: 0.7279 - val_accuracy: 0.7271\n",
      "Epoch 63/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.91 - ETA: 0s - loss: 0.2177 - accuracy: 0.91 - ETA: 0s - loss: 0.2180 - accuracy: 0.91 - ETA: 0s - loss: 0.2199 - accuracy: 0.90 - 0s 41us/step - loss: 0.2218 - accuracy: 0.9079 - val_loss: 0.7431 - val_accuracy: 0.7221\n",
      "Epoch 64/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.90 - ETA: 0s - loss: 0.2208 - accuracy: 0.91 - ETA: 0s - loss: 0.2180 - accuracy: 0.91 - ETA: 0s - loss: 0.2183 - accuracy: 0.91 - 0s 42us/step - loss: 0.2196 - accuracy: 0.9103 - val_loss: 0.7102 - val_accuracy: 0.7464\n",
      "Epoch 65/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.90 - ETA: 0s - loss: 0.2161 - accuracy: 0.90 - ETA: 0s - loss: 0.2209 - accuracy: 0.90 - ETA: 0s - loss: 0.2193 - accuracy: 0.90 - 0s 42us/step - loss: 0.2195 - accuracy: 0.9085 - val_loss: 0.7151 - val_accuracy: 0.7418\n",
      "Epoch 66/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.90 - ETA: 0s - loss: 0.2260 - accuracy: 0.90 - ETA: 0s - loss: 0.2238 - accuracy: 0.90 - ETA: 0s - loss: 0.2211 - accuracy: 0.90 - 0s 42us/step - loss: 0.2222 - accuracy: 0.9085 - val_loss: 0.7333 - val_accuracy: 0.7393\n",
      "Epoch 67/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.91 - ETA: 0s - loss: 0.2202 - accuracy: 0.90 - ETA: 0s - loss: 0.2179 - accuracy: 0.91 - ETA: 0s - loss: 0.2182 - accuracy: 0.91 - 0s 41us/step - loss: 0.2168 - accuracy: 0.9112 - val_loss: 0.7176 - val_accuracy: 0.7450\n",
      "Epoch 68/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.91 - ETA: 0s - loss: 0.2143 - accuracy: 0.91 - ETA: 0s - loss: 0.2103 - accuracy: 0.91 - ETA: 0s - loss: 0.2119 - accuracy: 0.91 - 0s 42us/step - loss: 0.2111 - accuracy: 0.9137 - val_loss: 0.7261 - val_accuracy: 0.7418\n",
      "Epoch 69/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.92 - ETA: 0s - loss: 0.2078 - accuracy: 0.91 - ETA: 0s - loss: 0.2096 - accuracy: 0.91 - ETA: 0s - loss: 0.2110 - accuracy: 0.91 - 0s 42us/step - loss: 0.2115 - accuracy: 0.9145 - val_loss: 0.7477 - val_accuracy: 0.7454\n",
      "Epoch 70/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.90 - ETA: 0s - loss: 0.1989 - accuracy: 0.91 - ETA: 0s - loss: 0.2116 - accuracy: 0.91 - ETA: 0s - loss: 0.2110 - accuracy: 0.91 - 0s 42us/step - loss: 0.2101 - accuracy: 0.9134 - val_loss: 0.7301 - val_accuracy: 0.7432\n",
      "Epoch 71/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.91 - ETA: 0s - loss: 0.2104 - accuracy: 0.91 - ETA: 0s - loss: 0.2073 - accuracy: 0.91 - ETA: 0s - loss: 0.2071 - accuracy: 0.91 - 0s 43us/step - loss: 0.2066 - accuracy: 0.9165 - val_loss: 0.7806 - val_accuracy: 0.7257\n",
      "Epoch 72/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.91 - ETA: 0s - loss: 0.2016 - accuracy: 0.91 - ETA: 0s - loss: 0.2011 - accuracy: 0.91 - ETA: 0s - loss: 0.2004 - accuracy: 0.91 - 0s 44us/step - loss: 0.2019 - accuracy: 0.9162 - val_loss: 0.7739 - val_accuracy: 0.7293\n",
      "Epoch 73/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.92 - ETA: 0s - loss: 0.1956 - accuracy: 0.92 - ETA: 0s - loss: 0.1932 - accuracy: 0.92 - ETA: 0s - loss: 0.1985 - accuracy: 0.92 - 0s 42us/step - loss: 0.1994 - accuracy: 0.9195 - val_loss: 0.8122 - val_accuracy: 0.7268\n",
      "Epoch 74/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.92 - ETA: 0s - loss: 0.1947 - accuracy: 0.92 - ETA: 0s - loss: 0.1989 - accuracy: 0.91 - ETA: 0s - loss: 0.1980 - accuracy: 0.91 - 0s 42us/step - loss: 0.1984 - accuracy: 0.9159 - val_loss: 0.7593 - val_accuracy: 0.7393\n",
      "Epoch 75/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.92 - ETA: 0s - loss: 0.1855 - accuracy: 0.92 - ETA: 0s - loss: 0.1993 - accuracy: 0.92 - ETA: 0s - loss: 0.1994 - accuracy: 0.92 - 0s 45us/step - loss: 0.1976 - accuracy: 0.9204 - val_loss: 0.7993 - val_accuracy: 0.7371\n",
      "Epoch 76/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.91 - ETA: 0s - loss: 0.1952 - accuracy: 0.91 - ETA: 0s - loss: 0.1902 - accuracy: 0.92 - ETA: 0s - loss: 0.1901 - accuracy: 0.92 - 0s 42us/step - loss: 0.1913 - accuracy: 0.9206 - val_loss: 0.7520 - val_accuracy: 0.7461\n",
      "Epoch 77/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1902 - accuracy: 0.92 - ETA: 0s - loss: 0.1915 - accuracy: 0.91 - ETA: 0s - loss: 0.1937 - accuracy: 0.91 - ETA: 0s - loss: 0.1939 - accuracy: 0.92 - 0s 44us/step - loss: 0.1971 - accuracy: 0.9192 - val_loss: 0.7867 - val_accuracy: 0.7446\n",
      "Epoch 78/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.92 - ETA: 0s - loss: 0.1907 - accuracy: 0.92 - ETA: 0s - loss: 0.1897 - accuracy: 0.92 - ETA: 0s - loss: 0.1923 - accuracy: 0.92 - 0s 42us/step - loss: 0.1932 - accuracy: 0.9218 - val_loss: 0.7912 - val_accuracy: 0.7454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.92 - ETA: 0s - loss: 0.1824 - accuracy: 0.92 - ETA: 0s - loss: 0.1851 - accuracy: 0.92 - ETA: 0s - loss: 0.1872 - accuracy: 0.92 - 0s 44us/step - loss: 0.1871 - accuracy: 0.9234 - val_loss: 0.7887 - val_accuracy: 0.7289\n",
      "Epoch 80/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.93 - ETA: 0s - loss: 0.1880 - accuracy: 0.92 - ETA: 0s - loss: 0.1842 - accuracy: 0.92 - ETA: 0s - loss: 0.1814 - accuracy: 0.92 - 0s 42us/step - loss: 0.1819 - accuracy: 0.9269 - val_loss: 0.8216 - val_accuracy: 0.7271\n",
      "Epoch 81/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.92 - ETA: 0s - loss: 0.1840 - accuracy: 0.92 - ETA: 0s - loss: 0.1845 - accuracy: 0.92 - ETA: 0s - loss: 0.1860 - accuracy: 0.92 - 0s 42us/step - loss: 0.1867 - accuracy: 0.9229 - val_loss: 0.7960 - val_accuracy: 0.7364\n",
      "Epoch 82/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.93 - ETA: 0s - loss: 0.1739 - accuracy: 0.93 - ETA: 0s - loss: 0.1802 - accuracy: 0.92 - ETA: 0s - loss: 0.1855 - accuracy: 0.92 - 0s 43us/step - loss: 0.1844 - accuracy: 0.9254 - val_loss: 0.7941 - val_accuracy: 0.7386\n",
      "Epoch 83/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.93 - ETA: 0s - loss: 0.1775 - accuracy: 0.92 - ETA: 0s - loss: 0.1791 - accuracy: 0.92 - ETA: 0s - loss: 0.1810 - accuracy: 0.92 - 0s 43us/step - loss: 0.1815 - accuracy: 0.9263 - val_loss: 0.8169 - val_accuracy: 0.7339\n",
      "Epoch 84/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.92 - ETA: 0s - loss: 0.1844 - accuracy: 0.92 - ETA: 0s - loss: 0.1834 - accuracy: 0.92 - ETA: 0s - loss: 0.1838 - accuracy: 0.92 - 0s 42us/step - loss: 0.1836 - accuracy: 0.9257 - val_loss: 0.8465 - val_accuracy: 0.7329\n",
      "Epoch 85/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.93 - ETA: 0s - loss: 0.1706 - accuracy: 0.93 - ETA: 0s - loss: 0.1741 - accuracy: 0.92 - ETA: 0s - loss: 0.1762 - accuracy: 0.92 - 0s 43us/step - loss: 0.1768 - accuracy: 0.9267 - val_loss: 0.8377 - val_accuracy: 0.7389\n",
      "Epoch 86/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.93 - ETA: 0s - loss: 0.1826 - accuracy: 0.92 - ETA: 0s - loss: 0.1754 - accuracy: 0.92 - ETA: 0s - loss: 0.1766 - accuracy: 0.92 - 0s 44us/step - loss: 0.1759 - accuracy: 0.9286 - val_loss: 0.8470 - val_accuracy: 0.7493\n",
      "Epoch 87/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.93 - ETA: 0s - loss: 0.1745 - accuracy: 0.92 - ETA: 0s - loss: 0.1722 - accuracy: 0.92 - ETA: 0s - loss: 0.1745 - accuracy: 0.92 - 0s 42us/step - loss: 0.1763 - accuracy: 0.9277 - val_loss: 0.7963 - val_accuracy: 0.7375\n",
      "Epoch 88/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.92 - ETA: 0s - loss: 0.1669 - accuracy: 0.93 - ETA: 0s - loss: 0.1745 - accuracy: 0.92 - ETA: 0s - loss: 0.1735 - accuracy: 0.93 - 0s 44us/step - loss: 0.1722 - accuracy: 0.9313 - val_loss: 0.8208 - val_accuracy: 0.7482\n",
      "Epoch 89/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.93 - ETA: 0s - loss: 0.1693 - accuracy: 0.93 - ETA: 0s - loss: 0.1667 - accuracy: 0.93 - ETA: 0s - loss: 0.1666 - accuracy: 0.93 - 0s 42us/step - loss: 0.1677 - accuracy: 0.9324 - val_loss: 0.8411 - val_accuracy: 0.7386\n",
      "Epoch 90/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.92 - ETA: 0s - loss: 0.1743 - accuracy: 0.92 - ETA: 0s - loss: 0.1703 - accuracy: 0.93 - ETA: 0s - loss: 0.1700 - accuracy: 0.93 - 0s 42us/step - loss: 0.1707 - accuracy: 0.9303 - val_loss: 0.8397 - val_accuracy: 0.7346\n",
      "Epoch 91/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.93 - ETA: 0s - loss: 0.1667 - accuracy: 0.93 - ETA: 0s - loss: 0.1682 - accuracy: 0.92 - ETA: 0s - loss: 0.1671 - accuracy: 0.93 - 0s 42us/step - loss: 0.1672 - accuracy: 0.9310 - val_loss: 0.8482 - val_accuracy: 0.7432\n",
      "Epoch 92/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.93 - ETA: 0s - loss: 0.1555 - accuracy: 0.93 - ETA: 0s - loss: 0.1553 - accuracy: 0.93 - ETA: 0s - loss: 0.1578 - accuracy: 0.93 - 0s 43us/step - loss: 0.1620 - accuracy: 0.9343 - val_loss: 0.8567 - val_accuracy: 0.7318\n",
      "Epoch 93/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.94 - ETA: 0s - loss: 0.1531 - accuracy: 0.94 - ETA: 0s - loss: 0.1604 - accuracy: 0.93 - ETA: 0s - loss: 0.1639 - accuracy: 0.93 - 0s 43us/step - loss: 0.1667 - accuracy: 0.9337 - val_loss: 0.8946 - val_accuracy: 0.7250\n",
      "Epoch 94/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.93 - ETA: 0s - loss: 0.1557 - accuracy: 0.93 - ETA: 0s - loss: 0.1522 - accuracy: 0.93 - ETA: 0s - loss: 0.1566 - accuracy: 0.93 - 0s 43us/step - loss: 0.1579 - accuracy: 0.9366 - val_loss: 0.8519 - val_accuracy: 0.7464\n",
      "Epoch 95/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.93 - ETA: 0s - loss: 0.1560 - accuracy: 0.93 - ETA: 0s - loss: 0.1568 - accuracy: 0.93 - ETA: 0s - loss: 0.1587 - accuracy: 0.93 - 0s 43us/step - loss: 0.1592 - accuracy: 0.9358 - val_loss: 0.8408 - val_accuracy: 0.7404\n",
      "Epoch 96/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.93 - ETA: 0s - loss: 0.1506 - accuracy: 0.94 - ETA: 0s - loss: 0.1511 - accuracy: 0.94 - ETA: 0s - loss: 0.1519 - accuracy: 0.93 - 0s 44us/step - loss: 0.1531 - accuracy: 0.9382 - val_loss: 0.8721 - val_accuracy: 0.7414\n",
      "Epoch 97/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.93 - ETA: 0s - loss: 0.1597 - accuracy: 0.93 - ETA: 0s - loss: 0.1551 - accuracy: 0.93 - ETA: 0s - loss: 0.1550 - accuracy: 0.93 - 0s 43us/step - loss: 0.1553 - accuracy: 0.9362 - val_loss: 0.9775 - val_accuracy: 0.7179\n",
      "Epoch 98/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.93 - ETA: 0s - loss: 0.1372 - accuracy: 0.94 - ETA: 0s - loss: 0.1468 - accuracy: 0.94 - ETA: 0s - loss: 0.1480 - accuracy: 0.94 - 0s 42us/step - loss: 0.1505 - accuracy: 0.9396 - val_loss: 0.8991 - val_accuracy: 0.7261\n",
      "Epoch 99/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.93 - ETA: 0s - loss: 0.1494 - accuracy: 0.94 - ETA: 0s - loss: 0.1538 - accuracy: 0.94 - ETA: 0s - loss: 0.1529 - accuracy: 0.94 - 0s 42us/step - loss: 0.1552 - accuracy: 0.9397 - val_loss: 0.8852 - val_accuracy: 0.7307\n",
      "Epoch 100/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.94 - ETA: 0s - loss: 0.1484 - accuracy: 0.94 - ETA: 0s - loss: 0.1518 - accuracy: 0.93 - ETA: 0s - loss: 0.1502 - accuracy: 0.93 - 0s 41us/step - loss: 0.1514 - accuracy: 0.9385 - val_loss: 0.9022 - val_accuracy: 0.7293\n"
     ]
    }
   ],
   "source": [
    "X = train_titles_sequences\n",
    "\n",
    "#y = train_df['OTHERS'] #1 model/label\n",
    "y = train_df[['EMPIRICAL','ENGINEERING','THEORETICAL','OTHERS']] #1 model/4 labels\n",
    "\n",
    "hist = model.fit(X, y, validation_split=0.1,\n",
    "                 epochs=100, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      2140\n",
      "           1       0.96      0.89      0.93      3391\n",
      "           2       0.96      0.94      0.95      3218\n",
      "           3       0.93      0.76      0.84       259\n",
      "\n",
      "   micro avg       0.94      0.91      0.93      9008\n",
      "   macro avg       0.94      0.88      0.90      9008\n",
      "weighted avg       0.94      0.91      0.93      9008\n",
      " samples avg       0.94      0.93      0.93      9008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Plot model accuracy\n",
    "history = pd.DataFrame(hist.history)\n",
    "plt.figure(figsize=(12,12));\n",
    "plt.plot(history[\"val_accuracy\"], 'r');\n",
    "plt.plot(history[\"accuracy\"], 'b');\n",
    "plt.xlabel('Epoch')\n",
    "plt.title(\"Accuracy with pretrained word vectors\");\n",
    "plt.show();\n",
    "\n",
    "#Print report\n",
    "\"\"\"\n",
    "## 1 model/label\n",
    "y_pred = [1 if pred>=0.8 else 0 for pred in model.predict(X)]\n",
    "print(classification_report(y, y_pred))\n",
    "\"\"\"\n",
    "## 1 model/4 labels\n",
    "y_pred = model.predict(X)\n",
    "for row in y_pred:\n",
    "    for i in range(4):\n",
    "        if row[i] >= 0.5:\n",
    "            row[i] = 1\n",
    "        else:\n",
    "            row[i] = 0\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = [1 if pred>=0.8 else 0 for pred in model.predict(test_titles_sequences)]\n",
    "\n",
    "y_test = model.predict(test_titles_sequences)\n",
    "for row in y_test:\n",
    "    for i in range(4):\n",
    "        if row[i] >= 0.5:\n",
    "            row[i] = int(1)\n",
    "        else:\n",
    "            row[i] = int(0)\n",
    "\n",
    "\n",
    "test_df[['EMPIRICAL','ENGINEERING','THEORETICAL','OTHERS']] = y_test\n",
    "test_df[['EMPIRICAL','ENGINEERING','THEORETICAL','OTHERS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPIRICAL</th>\n",
       "      <th>ENGINEERING</th>\n",
       "      <th>THEORETICAL</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>0.408150</td>\n",
       "      <td>0.52005</td>\n",
       "      <td>0.01740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.467064</td>\n",
       "      <td>0.491503</td>\n",
       "      <td>0.49961</td>\n",
       "      <td>0.13076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EMPIRICAL   ENGINEERING  THEORETICAL       OTHERS\n",
       "count  20000.000000  20000.000000  20000.00000  20000.00000\n",
       "mean       0.321500      0.408150      0.52005      0.01740\n",
       "std        0.467064      0.491503      0.49961      0.13076\n",
       "min        0.000000      0.000000      0.00000      0.00000\n",
       "25%        0.000000      0.000000      0.00000      0.00000\n",
       "50%        0.000000      0.000000      1.00000      0.00000\n",
       "75%        1.000000      1.000000      1.00000      0.00000\n",
       "max        1.000000      1.000000      1.00000      1.00000"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['EMPIRICAL','ENGINEERING','THEORETICAL','OTHERS']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id       T00001\n",
       "THEORETICAL         0\n",
       "ENGINEERING         0\n",
       "EMPIRICAL           0\n",
       "OTHERS              0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = read_file('task2_sample_submission.csv')\n",
    "#submission.loc[:20000, ['EMPIRICAL','ENGINEERING','THEORETICAL','OTHERS']] = test_df[['EMPIRICAL','ENGINEERING','THEORETICAL','OTHERS']]\n",
    "#submission.loc[:20000, ['EMPIRICAL','ENGINEERING','THEORETICAL','OTHERS']].astype(int)\n",
    "type(submission)\n",
    "submission.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>THEORETICAL</th>\n",
       "      <th>ENGINEERING</th>\n",
       "      <th>EMPIRICAL</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>T00001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>T00002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>T00003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>T00004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>T00005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39995</td>\n",
       "      <td>T39996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39996</td>\n",
       "      <td>T39997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39997</td>\n",
       "      <td>T39998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39998</td>\n",
       "      <td>T39999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39999</td>\n",
       "      <td>T40000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id THEORETICAL ENGINEERING EMPIRICAL OTHERS\n",
       "0       T00001           1           1         0      0\n",
       "1       T00002           0           1         0      0\n",
       "2       T00003           1           1         0      0\n",
       "3       T00004           1           0         1      0\n",
       "4       T00005           1           0         0      0\n",
       "...        ...         ...         ...       ...    ...\n",
       "39995   T39996           0           0         0      0\n",
       "39996   T39997           0           0         0      0\n",
       "39997   T39998           0           0         0      0\n",
       "39998   T39999           0           0         0      0\n",
       "39999   T40000           0           0         0      0\n",
       "\n",
       "[40000 rows x 5 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'submission.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6430\n",
      "8163\n",
      "10401\n",
      "259\n"
     ]
    }
   ],
   "source": [
    "print(sum([int(i) for i in test_df['EMPIRICAL']]))\n",
    "print(sum([int(i) for i in test_df['ENGINEERING']]))\n",
    "print(sum([int(i) for i in test_df['THEORETICAL']]))\n",
    "print(sum([int(i) for i in test_df['OTHERS']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(test_df)):\n",
    "    if test_df['OTHERS'][i] == 1:\n",
    "        if test_df['EMPIRICAL'][i]==1 or test_df['ENGINEERING'][i]==1 or test_df['THEORETICAL'][i]==1:\n",
    "            test_df.loc[i, 'OTHERS'] = 0\n",
    "            count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_df[['Id','THEORETICAL','ENGINEERING','EMPIRICAL','OTHERS']]\n",
    "type(submission)\n",
    "submission.to_csv(r'submission.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-800f804d5e2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'THEORETICAL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ENGINEERING'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'EMPIRICAL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'OTHERS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;34m\"first argument must be an iterable of pandas \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                 \u001b[1;34m\"objects, you passed an object of type \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m                 \u001b[1;34m'\"{name}\"'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             )\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "pd.concat(submission, test_df[['Id','THEORETICAL','ENGINEERING','EMPIRICAL','OTHERS']], ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
